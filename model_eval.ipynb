{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33cb6ddc-981c-41e5-b32e-b14b85fbc89e",
   "metadata": {},
   "source": [
    "# 2B –ú–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d47ea8-91a4-47a7-b6ba-208d4780ba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# üîπ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å \n",
    "model_name = \"google/gemma-2b-it\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "# üîπ –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞\n",
    "llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b554395-54cf-4399-bc0d-a0eb764a7ae6",
   "metadata": {},
   "source": [
    "# –ü–æ–¥–≥—Ä—É–∂–∞–µ–º 8B –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566a5f9c-11fa-41df-b9a8-6a25c97ed846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab5dc2c25534cc8a2205e2e9606ae3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "model_name = \"t-bank-ai/T-lite-instruct-0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             quantization_config=quant_config,\n",
    "                                             device_map=\"auto\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è –º–æ–¥–µ–ª–∏\n",
    "llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c19cb7d-95bb-4d25-bd48-3db23cf5ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def extract_location(query: str):\n",
    "    \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä–∞–Ω—ã –∏ –≥–æ—Ä–æ–¥–∞ —Å –ø–æ–º–æ—â—å—é LLM –≤ —Ñ–æ—Ä–º–∞—Ç–µ few-shot.\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"–ò–∑–≤–ª–µ–∫–∏ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç—Ä–∞–Ω –∏ –≥–æ—Ä–æ–¥–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞. –û—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.\n",
    "\n",
    "    –ü—Ä–∏–º–µ—Ä 1:\n",
    "    –¢–µ–∫—Å—Ç: \"–ö–∞–∫–∏–µ –¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –µ—Å—Ç—å –≤ –ú–æ—Å–∫–≤–µ –∏ –ü–∞—Ä–∏–∂–µ?\"\n",
    "    –û—Ç–≤–µ—Ç:\n",
    "    {{\n",
    "      \"cities\": [\"–ú–æ—Å–∫–≤–∞\", \"–ü–∞—Ä–∏–∂\"],\n",
    "      \"countries\": [\"–†–æ—Å—Å–∏—è\", \"–§—Ä–∞–Ω—Ü–∏—è\"]\n",
    "    }}\n",
    "    \n",
    "    –ü—Ä–∏–º–µ—Ä 2:\n",
    "    –¢–µ–∫—Å—Ç: \"–ß—Ç–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ –ë–µ—Ä–ª–∏–Ω–µ, –õ–æ–Ω–¥–æ–Ω–µ –∏ –ò—Ç–∞–ª–∏–∏?\"\n",
    "    –û—Ç–≤–µ—Ç:\n",
    "    {{\n",
    "      \"cities\": [\"–ë–µ—Ä–ª–∏–Ω\", \"–õ–æ–Ω–¥–æ–Ω\"],\n",
    "      \"countries\": [\"–ì–µ—Ä–º–∞–Ω–∏—è\", \"–í–µ–ª–∏–∫–æ–±—Ä–∏—Ç–∞–Ω–∏—è\", \"–ò—Ç–∞–ª–∏—è\"]\n",
    "    }}\n",
    "    \n",
    "    –ü—Ä–∏–º–µ—Ä 3:\n",
    "    –¢–µ–∫—Å—Ç: \"{query}\"\n",
    "    –û—Ç–≤–µ—Ç:\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm_pipeline(prompt, max_new_tokens=100, do_sample=False)\n",
    "    response_text = response[0][\"generated_text\"]\n",
    "\n",
    "    try:\n",
    "        # –†–∞–∑–¥–µ–ª–∏–º –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ —Å–ª–æ–≤—É '–û—Ç–≤–µ—Ç' –∏ –≤–æ–∑—å–º—ë–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç\n",
    "        parts = response_text.split(\"–û—Ç–≤–µ—Ç:\")\n",
    "        answer_part = parts[3] \n",
    "\n",
    "        # –ù–∞–π–¥—ë–º –ø–µ—Ä–≤—É—é –ø–æ–¥—Å—Ç—Ä–æ–∫—É –æ—Ç \"{\" –¥–æ \"}\" \n",
    "        json_start = answer_part.find(\"{\")\n",
    "        json_end = answer_part.find(\"}\") + 2\n",
    "\n",
    "        if json_start == -1 or json_end == -1:\n",
    "            raise ValueError(\"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ JSON-–±–ª–æ–∫\")\n",
    "\n",
    "        json_str = answer_part[json_start:json_end]\n",
    "        result = json.loads(json_str)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {e}\")\n",
    "        result = {\"cities\": [], \"countries\": []}\n",
    "\n",
    "    return result\n",
    "\n",
    "#user_query = \"–ß—Ç–æ –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ –ö–∞–∑–∞–Ω–∏ –∏ –≤ –ì–µ—Ä–º–∞–Ω–∏–∏?\"\n",
    "#print(extract_location(user_query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e32ab-3e4f-47f3-b63b-f4a4882bc63b",
   "metadata": {},
   "source": [
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f86edc-13fb-4d85-bb4f-83fa7d3d1b77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "```\n",
    "–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å —Å–º–æ–∂–µ—Ç –≤—ã—á–ª–µ–Ω—è—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç—Ä–∞–Ω –∏ –≥–æ—Ä–æ–¥–æ–≤ –∏–∑ –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ –º—ã –º–æ–∂–µ–º –æ—Ü–µ–Ω–∏—Ç—å —Ä–µ—Ç—Ä–∏–≤–µ—Ä –ø—É—Ç–µ–º –æ—Ü–µ–Ω–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –∑–∞–ø—Ä–æ—Å—É. –¢–∫ –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º –º—ã –±—É–¥–µ–º —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —á–∞–Ω–∫–∏ –ø–æ –º–µ—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–°—Ç—Ä–∞–Ω–∞, –≥–æ—Ä–æ–¥) –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –º–æ–¥–µ–ª–∏ –Ω–µ –±—É–¥–µ—Ç –ø–æ–ø–∞–¥–∞—Ç—å –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd90a9-c423-480c-9e22-a0655fc56b59",
   "metadata": {},
   "source": [
    "## –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d22d94cf-4f00-4395-bb32-c4431ad35175",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"–ö–∞–∫–∏–µ –¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å—Ç–æ–∏—Ç –ø–æ—Å–µ—Ç–∏—Ç—å –≤ –ú–æ—Å–∫–≤–µ –∏ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥–µ?\",\n",
    "    \"–ß—Ç–æ –ª—É—á—à–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏–∑ –µ–¥—ã –≤ –ü–∞—Ä–∏–∂–µ –∏ –õ–∏–æ–Ω–µ?\",\n",
    "    \"–ö–∞–∫–∏–µ –º—É–∑–µ–∏ –µ—Å—Ç—å –≤ –ë–µ—Ä–ª–∏–Ω–µ –∏ –ú—é–Ω—Ö–µ–Ω–µ?\",\n",
    "    \"–ì–¥–µ –º–æ–∂–Ω–æ –ø–æ–∫–∞—Ç–∞—Ç—å—Å—è –Ω–∞ –≥–æ–Ω–¥–æ–ª–∞—Ö –≤ –ò—Ç–∞–ª–∏–∏?\",\n",
    "    \"–ö–∞–∫–æ–π –ø–ª—è–∂–Ω—ã–π –æ—Ç–¥—ã—Ö –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –≤–æ –§–ª–æ—Ä–µ–Ω—Ü–∏–∏ –∏–ª–∏ –í–µ–Ω–µ—Ü–∏–∏?\",\n",
    "    \"–ö–∞–∫–æ–π –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –†–∏–º–µ?\",\n",
    "    \"–ö–∞–∫–æ–≤–∞ –∏—Å—Ç–æ—Ä–∏—è –ö—Ä–∞—Å–Ω–æ–π –ø–ª–æ—â–∞–¥–∏ –≤ –ú–æ—Å–∫–≤–µ?\",\n",
    "    \"–ö–∞–∫–∏–µ –∑–∞–º–∫–∏ –º–æ–∂–Ω–æ –ø–æ—Å–µ—Ç–∏—Ç—å –≤–æ –§—Ä–∞–Ω—Ü–∏–∏?\",\n",
    "    \"–ö–∞–∫–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–¥–∞–Ω–∏—è –µ—Å—Ç—å –≤ –ë–µ—Ä–ª–∏–Ω–µ?\",\n",
    "    \"–ß—Ç–æ —Å—Ç–æ–∏—Ç –ø–æ—Å–µ—Ç–∏—Ç—å –≤ –ö–∞–∑–∞–Ω–∏ —Ç—É—Ä–∏—Å—Ç—É –≤–ø–µ—Ä–≤—ã–µ?\"\n",
    "]\n",
    "\n",
    "expected_entities = [\n",
    "    {\"cities\": [\"–ú–æ—Å–∫–≤–∞\", \"–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥\"], \"countries\": [\"–†–æ—Å—Å–∏—è\"]},\n",
    "    {\"cities\": [\"–ü–∞—Ä–∏–∂\", \"–õ–∏–æ–Ω\"], \"countries\": [\"–§—Ä–∞–Ω—Ü–∏—è\"]},\n",
    "    {\"cities\": [\"–ë–µ—Ä–ª–∏–Ω\", \"–ú—é–Ω—Ö–µ–Ω\"], \"countries\": [\"–ì–µ—Ä–º–∞–Ω–∏—è\"]},\n",
    "    {\"cities\": [], \"countries\": [\"–ò—Ç–∞–ª–∏—è\"]},  # –í–æ–ø—Ä–æ—Å –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –≥–æ—Ä–æ–¥–æ–≤\n",
    "    {\"cities\": [\"–§–ª–æ—Ä–µ–Ω—Ü–∏—è\", \"–í–µ–Ω–µ—Ü–∏—è\"], \"countries\": [\"–ò—Ç–∞–ª–∏—è\"]},\n",
    "    {\"cities\": [\"–†–∏–º\"], \"countries\": [\"–ò—Ç–∞–ª–∏—è\"]},\n",
    "    {\"cities\": [\"–ú–æ—Å–∫–≤–∞\"], \"countries\": [\"–†–æ—Å—Å–∏—è\"]},\n",
    "    {\"cities\": [], \"countries\": [\"–§—Ä–∞–Ω—Ü–∏—è\"]},\n",
    "    {\"cities\": [\"–ë–µ—Ä–ª–∏–Ω\"], \"countries\": [\"–ì–µ—Ä–º–∞–Ω–∏—è\"]},\n",
    "    {\"cities\": [\"–ö–∞–∑–∞–Ω—å\"], \"countries\": [\"–†–æ—Å—Å–∏—è\"]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e262ec-c186-4035-8592-00ff5b8f2d52",
   "metadata": {},
   "source": [
    "## –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π\n",
    "\n",
    "### 1. Full Match Accuracy \n",
    "\n",
    "–≠—Ç–∞ –º–µ—Ç—Ä–∏–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ç–æ—á–Ω–æ –º–æ–¥–µ–ª—å –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –Ω—É–∂–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ (–≥–æ—Ä–æ–¥–∞ –∏ —Å—Ç—Ä–∞–Ω—ã).\n",
    "\n",
    "**–ö–∞–∫ —Å—á–∏—Ç–∞–µ—Ç—Å—è**:\n",
    "\n",
    "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è, —Å–æ–≤–ø–∞–¥–∞—é—Ç –ª–∏ –æ–±–∞ —Å–ø–∏—Å–∫–∞ ‚Äî –∏ —Å—Ç—Ä–∞–Ω, –∏ –≥–æ—Ä–æ–¥–æ–≤ ‚Äî –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å –æ–∂–∏–¥–∞–µ–º—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏:\n",
    "\n",
    "–ï—Å–ª–∏ —Å–æ–≤–ø–∞–¥–∞–µ—Ç ‚Äî —Å—á–∏—Ç–∞–µ–º 1 –±–∞–ª–ª.\n",
    "–ï—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ –ª–∏—à–Ω—è—è –∏–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω–Ω–∞—è —Å—É—â–Ω–æ—Å—Ç—å ‚Äî 0 –±–∞–ª–ª–æ–≤.\n",
    "\n",
    "–ó–∞—Ç–µ–º –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –¥–æ–ª—è —Ç–∞–∫–∏—Ö –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤–µ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.\n",
    "\n",
    "\n",
    "### 2. IoU (Intersection over Union)\n",
    "\n",
    "–ú–µ—Ç—Ä–∏–∫–∞ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –º–µ–∂–¥—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º–∏ –∏ –æ–∂–∏–¥–∞–µ–º—ã–º–∏ —Å—É—â–Ω–æ—Å—Ç—è–º–∏ ‚Äî —Ç–æ –µ—Å—Ç—å –Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –æ–Ω–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç, –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ –∏–¥–µ–∞–ª—å–Ω–æ.\n",
    "\n",
    "**–ö–∞–∫ —Å—á–∏—Ç–∞–µ—Ç—Å—è**:\n",
    "\n",
    "–°–Ω–∞—á–∞–ª–∞ –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è –≥–æ—Ä–æ–¥–æ–≤ –∏ –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è —Å—Ç—Ä–∞–Ω:\n",
    "\n",
    "–°—á–∏—Ç–∞–µ—Ç—Å—è, —Å–∫–æ–ª—å–∫–æ —Å—É—â–Ω–æ—Å—Ç–µ–π –±—ã–ª–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ –≤–µ—Ä–Ω–æ.\n",
    "–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç—Å—è —ç—Ç–æ —Å –æ–±—â–∏–º —á–∏—Å–ª–æ–º –≤—Å–µ—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ –∏ —ç—Ç–∞–ª–æ–Ω–µ (—Ç–æ –µ—Å—Ç—å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ–º).\n",
    "–ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –≤ –æ–¥–Ω–æ —Å—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ.\n",
    "\n",
    "–ó–∞—Ç–µ–º IoU —É—Å—Ä–µ–¥–Ω—è–µ—Ç—Å—è –ø–æ –≤—Å–µ–º –∑–∞–ø—Ä–æ—Å–∞–º\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dffeb719-4141-479e-97e6-1cbfe5a89687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def evaluate_retriever(predicted_entities: List[Dict],\n",
    "                       queries: List[str],\n",
    "                       expected: List[Dict]):\n",
    "    \"\"\"–û—Ü–µ–Ω–∏–≤–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å –≤—ã–¥–µ–ª–µ–Ω–∏—è —Å—Ç—Ä–∞–Ω –∏ –≥–æ—Ä–æ–¥–æ–≤ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏.\"\"\"\n",
    "\n",
    "    correct_full_predictions = 0\n",
    "    total_iou = 0\n",
    "\n",
    "    for i, (pred, true) in enumerate(zip(predicted_entities, expected)):\n",
    "        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã\n",
    "        pred_cities = set(pred.get(\"cities\", []))\n",
    "        pred_countries = set(pred.get(\"countries\", []))\n",
    "\n",
    "        true_cities = set(true.get(\"cities\", []))\n",
    "        true_countries = set(true.get(\"countries\", []))\n",
    "\n",
    "        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ\n",
    "        if pred_cities == true_cities and pred_countries == true_countries:\n",
    "            correct_full_predictions += 1\n",
    "\n",
    "        # IoU –ø–æ –≥–æ—Ä–æ–¥–∞–º\n",
    "        union_cities = pred_cities | true_cities\n",
    "        inter_cities = pred_cities & true_cities\n",
    "        cities_iou = len(inter_cities) / len(union_cities) if union_cities else 1.0\n",
    "\n",
    "        # IoU –ø–æ —Å—Ç—Ä–∞–Ω–∞–º\n",
    "        union_countries = pred_countries | true_countries\n",
    "        inter_countries = pred_countries & true_countries\n",
    "        countries_iou = len(inter_countries) / len(union_countries) if union_countries else 1.0\n",
    "\n",
    "        avg_iou = (cities_iou + countries_iou) / 2\n",
    "        total_iou += avg_iou\n",
    "\n",
    "        print(f\"\\n–í–æ–ø—Ä–æ—Å {i+1}: {queries[i]}\")\n",
    "        print(f\"–û–∂–∏–¥–∞–ª–æ—Å—å: {true}\")\n",
    "        print(f\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {pred}\")\n",
    "        print(f\"IoU: {avg_iou:.2f}\")\n",
    "        print(f\"–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {int(pred_cities == true_cities and pred_countries == true_countries)}\")\n",
    "\n",
    "    print(\"\\n**–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞**\")\n",
    "    print(f\"–ü–æ–ª–Ω–æ—Å—Ç—å—é –≤–µ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {correct_full_predictions / len(queries):.2f}\")\n",
    "    print(f\"–°—Ä–µ–¥–Ω–∏–π IoU: {total_iou / len(queries):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "55876588-9ca8-4327-a2ec-f8e3a8b60dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò–Ω—Ñ–µ—Ä–µ–Ω—Å–∏–º –º–æ–¥–µ–ª—å –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç—ã\n",
    "predicted_entities = [extract_location(query) for query in test_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61f418d8-dff9-4f6d-89c4-2bff195eb1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cities': ['–ú–æ—Å–∫–≤–∞', '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥'], 'countries': ['–†–æ—Å—Å–∏—è', '–†–æ—Å—Å–∏—è']},\n",
       " {'cities': ['–ü–∞—Ä–∏–∂', '–õ–∏–æ–Ω'], 'countries': ['–§—Ä–∞–Ω—Ü–∏—è']},\n",
       " {'cities': ['–ë–µ—Ä–ª–∏–Ω', '–ú—é–Ω—Ö–µ–Ω'], 'countries': ['–ì–µ—Ä–º–∞–Ω–∏—è', '–ì–µ—Ä–º–∞–Ω–∏—è']},\n",
       " {'cities': ['–ò—Ç–∞–ª–∏—è'], 'countries': ['–ò—Ç–∞–ª–∏—è']},\n",
       " {'cities': ['–§–ª–æ—Ä–µ–Ω—Ü–∏—è', '–í–µ–Ω–µ—Ü–∏—è'], 'countries': ['–ò—Ç–∞–ª–∏—è']},\n",
       " {'cities': ['–†–∏–º'], 'countries': ['–ò—Ç–∞–ª–∏—è']},\n",
       " {'cities': ['–ú–æ—Å–∫–≤–∞'], 'countries': ['–†–æ—Å—Å–∏—è']},\n",
       " {'cities': [], 'countries': ['–§—Ä–∞–Ω—Ü–∏—è']},\n",
       " {'cities': ['–ë–µ—Ä–ª–∏–Ω'], 'countries': ['–ì–µ—Ä–º–∞–Ω–∏—è']},\n",
       " {'cities': ['–ö–∞–∑–∞–Ω—å'], 'countries': ['–†–æ—Å—Å–∏—è']}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "069a9ac4-e85b-4f8f-9eed-52786d32981f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–í–æ–ø—Ä–æ—Å 1: –ö–∞–∫–∏–µ –¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å—Ç–æ–∏—Ç –ø–æ—Å–µ—Ç–∏—Ç—å –≤ –ú–æ—Å–∫–≤–µ –∏ –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥–µ?\n",
      "–û–∂–∏–¥–∞–ª–æ—Å—å: {'cities': ['–ú–æ—Å–∫–≤–∞', '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥'], 'countries': ['–†–æ—Å—Å–∏—è']}\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {'cities': ['–ú–æ—Å–∫–≤–∞', '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥'], 'countries': ['–†–æ—Å—Å–∏—è', '–†–æ—Å—Å–∏—è']}\n",
      "IoU: 1.00\n",
      "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: 1\n",
      "\n",
      "–í–æ–ø—Ä–æ—Å 2: –ß—Ç–æ –ª—É—á—à–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏–∑ –µ–¥—ã –≤ –ü–∞—Ä–∏–∂–µ –∏ –õ–∏–æ–Ω–µ?\n",
      "–û–∂–∏–¥–∞–ª–æ—Å—å: {'cities': ['–ü–∞—Ä–∏–∂', '–õ–∏–æ–Ω'], 'countries': ['–§—Ä–∞–Ω—Ü–∏—è']}\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {'cities': ['–ü–∞—Ä–∏–∂', '–õ–∏–æ–Ω'], 'countries': ['–§—Ä–∞–Ω—Ü–∏—è']}\n",
      "IoU: 1.00\n",
      "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: 1\n",
      "\n",
      "–í–æ–ø—Ä–æ—Å 3: –ö–∞–∫–∏–µ –º—É–∑–µ–∏ –µ—Å—Ç—å –≤ –ë–µ—Ä–ª–∏–Ω–µ –∏ –ú—é–Ω—Ö–µ–Ω–µ?\n",
      "–û–∂–∏–¥–∞–ª–æ—Å—å: {'cities': ['–ë–µ—Ä–ª–∏–Ω', '–ú—é–Ω—Ö–µ–Ω'], 'countries': ['–ì–µ—Ä–º–∞–Ω–∏—è']}\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {'cities': ['–ë–µ—Ä–ª–∏–Ω', '–ú—é–Ω—Ö–µ–Ω'], 'countries': ['–ì–µ—Ä–º–∞–Ω–∏—è', '–ì–µ—Ä–º–∞–Ω–∏—è']}\n",
      "IoU: 1.00\n",
      "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: 1\n",
      "\n",
      "–í–æ–ø—Ä–æ—Å 4: –ì–¥–µ –º–æ–∂–Ω–æ –ø–æ–∫–∞—Ç–∞—Ç—å—Å—è –Ω–∞ –≥–æ–Ω–¥–æ–ª–∞—Ö –≤ –ò—Ç–∞–ª–∏–∏?\n",
      "–û–∂–∏–¥–∞–ª–æ—Å—å: {'cities': [], 'countries': ['–ò—Ç–∞–ª–∏—è']}\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {'cities': ['–ò—Ç–∞–ª–∏—è'], 'countries': ['–ò—Ç–∞–ª–∏—è']}\n",
      "IoU: 0.50\n",
      "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: 0\n",
      "\n",
      "–í–æ–ø—Ä–æ—Å 5: –ö–∞–∫–æ–π –ø–ª—è–∂–Ω—ã–π –æ—Ç–¥—ã—Ö –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –≤–æ –§–ª–æ—Ä–µ–Ω—Ü–∏–∏ –∏–ª–∏ –í–µ–Ω–µ—Ü–∏–∏?\n",
      "–û–∂–∏–¥–∞–ª–æ—Å—å: {'cities': ['–§–ª–æ—Ä–µ–Ω—Ü–∏—è', '–í–µ–Ω–µ—Ü–∏—è'], 'countries': ['–ò—Ç–∞–ª–∏—è']}\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {'cities': ['–§–ª–æ—Ä–µ–Ω—Ü–∏—è', '–í–µ–Ω–µ—Ü–∏—è'], 'countries': ['–ò—Ç–∞–ª–∏—è']}\n",
      "IoU: 1.00\n",
      "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: 1\n",
      "\n",
      "–í–æ–ø—Ä–æ—Å 6: –ö–∞–∫–æ–π –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –†–∏–º–µ?\n",
      "–û–∂–∏–¥–∞–ª–æ—Å—å: {'cities': ['–†–∏–º'], 'countries': ['–ò—Ç–∞–ª–∏—è']}\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {'cities': ['–†–∏–º'], 'countries': ['–ò—Ç–∞–ª–∏—è']}\n",
      "IoU: 1.00\n",
      "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: 1\n",
      "\n",
      "–í–æ–ø—Ä–æ—Å 7: –ö–∞–∫–æ–≤–∞ –∏—Å—Ç–æ—Ä–∏—è –ö—Ä–∞—Å–Ω–æ–π –ø–ª–æ—â–∞–¥–∏ –≤ –ú–æ—Å–∫–≤–µ?\n",
      "–û–∂–∏–¥–∞–ª–æ—Å—å: {'cities': ['–ú–æ—Å–∫–≤–∞'], 'countries': ['–†–æ—Å—Å–∏—è']}\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {'cities': ['–ú–æ—Å–∫–≤–∞'], 'countries': ['–†–æ—Å—Å–∏—è']}\n",
      "IoU: 1.00\n",
      "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: 1\n",
      "\n",
      "–í–æ–ø—Ä–æ—Å 8: –ö–∞–∫–∏–µ –∑–∞–º–∫–∏ –º–æ–∂–Ω–æ –ø–æ—Å–µ—Ç–∏—Ç—å –≤–æ –§—Ä–∞–Ω—Ü–∏–∏?\n",
      "–û–∂–∏–¥–∞–ª–æ—Å—å: {'cities': [], 'countries': ['–§—Ä–∞–Ω—Ü–∏—è']}\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {'cities': [], 'countries': ['–§—Ä–∞–Ω—Ü–∏—è']}\n",
      "IoU: 1.00\n",
      "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: 1\n",
      "\n",
      "–í–æ–ø—Ä–æ—Å 9: –ö–∞–∫–∏–µ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–¥–∞–Ω–∏—è –µ—Å—Ç—å –≤ –ë–µ—Ä–ª–∏–Ω–µ?\n",
      "–û–∂–∏–¥–∞–ª–æ—Å—å: {'cities': ['–ë–µ—Ä–ª–∏–Ω'], 'countries': ['–ì–µ—Ä–º–∞–Ω–∏—è']}\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {'cities': ['–ë–µ—Ä–ª–∏–Ω'], 'countries': ['–ì–µ—Ä–º–∞–Ω–∏—è']}\n",
      "IoU: 1.00\n",
      "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: 1\n",
      "\n",
      "–í–æ–ø—Ä–æ—Å 10: –ß—Ç–æ —Å—Ç–æ–∏—Ç –ø–æ—Å–µ—Ç–∏—Ç—å –≤ –ö–∞–∑–∞–Ω–∏ —Ç—É—Ä–∏—Å—Ç—É –≤–ø–µ—Ä–≤—ã–µ?\n",
      "–û–∂–∏–¥–∞–ª–æ—Å—å: {'cities': ['–ö–∞–∑–∞–Ω—å'], 'countries': ['–†–æ—Å—Å–∏—è']}\n",
      "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {'cities': ['–ö–∞–∑–∞–Ω—å'], 'countries': ['–†–æ—Å—Å–∏—è']}\n",
      "IoU: 1.00\n",
      "–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: 1\n",
      "\n",
      "**–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞**\n",
      "**–ü–æ–ª–Ω–æ—Å—Ç—å—é –≤–µ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π**: 0.90\n",
      "–°—Ä–µ–¥–Ω–∏–π IoU: 0.95\n"
     ]
    }
   ],
   "source": [
    "evaluate_retriever(predicted_entities, test_queries, expected_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0548a8f-facd-4901-9dcd-5769e57ed35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1352c43d-0f1c-4a12-8830-664211e0dc97",
   "metadata": {},
   "source": [
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e50a4-63c8-4bfb-953d-2fd0e8644790",
   "metadata": {},
   "source": [
    "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "378edb91-0ea9-4a2a-b6a2-fff8ec1fc502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_17252\\1559281647.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_17252\\1559281647.py:12: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n"
     ]
    }
   ],
   "source": [
    "from chromadb import Client\n",
    "import chromadb\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–º–±–µ–¥–¥–µ—Ä FRIDA\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"ai-forever/FRIDA\"\n",
    ")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º Chroma DB \n",
    "db = Chroma(\n",
    "    embedding_function=embedding,\n",
    "    persist_directory=\"chroma_storage\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "574156bf-1070-459a-843b-d30ff85cde96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query: str, top_k: int):\n",
    "    \"\"\"\n",
    "    –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –≥–æ—Ä–æ–¥–∞–º, –∑–∞—Ç–µ–º fallback –Ω–∞ —Å—Ç—Ä–∞–Ω—É.\n",
    "    \"\"\"\n",
    "    \n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–∞–Ω—ã –∏ –≥–æ—Ä–æ–¥–∞\n",
    "    location = extract_location(query)\n",
    "    cities = location.get(\"cities\", [])\n",
    "    countries = location.get(\"countries\", [])\n",
    "\n",
    "    docs = []\n",
    "\n",
    "    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∏—Å–∫–∞—Ç—å –ø–æ –≥–æ—Ä–æ–¥–∞–º \n",
    "    if cities:\n",
    "        city_filter = {\"city\": {\"$in\": cities}}\n",
    "\n",
    "        try:\n",
    "            retriever = db.as_retriever(search_kwargs={\"filter\": city_filter, \"k\": top_k})\n",
    "            docs = retriever.get_relevant_documents(query)\n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –≥–æ—Ä–æ–¥–∞–º: {e}\")\n",
    "\n",
    "    # –ï—Å–ª–∏ –ø–æ –≥–æ—Ä–æ–¥–∞–º –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–±—É–µ–º –ø–æ —Å—Ç—Ä–∞–Ω–∞–º\n",
    "    if not docs and countries:\n",
    "        country_filter = {\"country\": {\"$in\": countries}}\n",
    "\n",
    "        try:\n",
    "            retriever = db.as_retriever(search_kwargs={\"filter\": country_filter, \"k\": top_k})\n",
    "            docs = retriever.get_relevant_documents(query)\n",
    "        except Exception as e:\n",
    "            print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º: {e}\")\n",
    "\n",
    "    # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ \n",
    "    if not docs:\n",
    "        return \"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –ø–æ —É–∫–∞–∑–∞–Ω–Ω—ã–º —Å—Ç—Ä–∞–Ω–∞–º –∏–ª–∏ –≥–æ—Ä–æ–¥–∞–º.\"\n",
    "\n",
    "    # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å search_document:\n",
    "    context = \"\\n\\n\".join(\n",
    "        doc.page_content.replace(\"search_document:\", \"\").strip() for doc in docs\n",
    "    )\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7523701-2624-415b-99c7-44785260778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query: str, context: str, max_new_tokens: int = 300) -> str:\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é LLM –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n",
    "    \n",
    "    :param query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    :param context: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (–∏–∑ –±–∞–∑—ã)\n",
    "    :param max_new_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ\n",
    "    :return: –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "             –¢—ã ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫.\n",
    "             –ò—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\n",
    "                \n",
    "             –ö–æ–Ω—Ç–µ–∫—Å—Ç:\n",
    "             {context}\n",
    "                \n",
    "             –í–æ–ø—Ä–æ—Å: {query}\n",
    "             –û—Ç–≤–µ—Ç:\n",
    "             \"\"\"\n",
    "\n",
    "    response = llm_pipeline(prompt, max_new_tokens=max_new_tokens)\n",
    "    response = response[0][\"generated_text\"].split(\"–û—Ç–≤–µ—Ç:\")[-1].strip() # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac83dab-3141-4d3d-8d1f-79b463285b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_pipeline(query: str, top_k: int = 3, debug: bool = False) -> str:\n",
    "    \"\"\" \n",
    "    –ü–∞–π–ø–ª–∞–π–Ω —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ \n",
    "\n",
    "    :param query: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    :param top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç –º–æ–¥–µ–ª–∏\n",
    "    :param debug: –§–ª–∞–≥ –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤–æ–ø—Ä–æ—Å–∞ —Å –ø–æ–¥–∞–≤–∞–µ–º—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n",
    "    :return: –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏\n",
    "    \"\"\"\n",
    "    \n",
    "    context = retrieve_documents(query, top_k) # —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≥–æ—Ä–æ–¥–∞–º –∏ —Å—Ç—Ä–∞–Ω–∞–º –¥–æ–∫—É–º–µ–Ω—Ç—ã, –∑–∞—Ç–µ–º –æ—Å—Ç–∞–≤–ª—è–µ–º top-k –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å—É\n",
    "\n",
    "    if debug:\n",
    "        print(f\"–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\\n{query}\")\n",
    "        print(\"\\n\" + \"*\" * 100 + \"\\n\")\n",
    "        print(f\"–ù–∞–π–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:\\n{context}\")\n",
    "        print(\"\\n\" + \"*\" * 100 + \"\\n\")\n",
    "    answer = generate_answer(query, context, max_new_tokens=300) # –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1638f0-31f6-42d0-afee-64292da43e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d1781b1-da45-470b-8957-ae304670cbf0",
   "metadata": {},
   "source": [
    "# –ú–µ—Ç—Ä–∏–∫–∞ –æ—Ü–µ–Ω–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af22c989-1886-4f6e-b5e2-2c6d1b8b9523",
   "metadata": {},
   "source": [
    "–ë—É–¥–µ–º –æ—Ü–µ–Ω–∏–≤–∞—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —ç—Ç–∞–ª–æ–Ω–Ω–æ–º—É –¥–ª—è –Ω–∞–±–æ—Ä–∞ –∏–∑ 10 –≤–æ–ø—Ä–æ—Å–æ–≤. \n",
    "\n",
    "–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è —Å –ø–æ–º–æ—â—å—é –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏ –Ω–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞—Ö –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –æ—Ç –≤–Ω–µ—à–Ω–µ–π –º–æ–¥–µ–ª–∏ FRIDA\n",
    "\n",
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –¥–ª—è –∫–∞–∂–¥–æ–π —Ç—Ä–æ–π–∫–∏ (–≤–æ–ø—Ä–æ—Å | —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞—à–µ–π LLM –æ—Ç–≤–µ—Ç| —ç—Ç–∞–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –≤—Ä—É—á–Ω—É—é) - —É –Ω–∞—Å –±—É–¥–µ—Ç –æ—Ü–µ–Ω–∫–∞ –æ—Ç 0 –¥–æ 1. –í –∫–æ–Ω—Ü–µ –ø—Ä–æ—Å—Ç–æ —É—Å—Ä–µ–¥–Ω–∏–º –æ—Ü–µ–Ω–∫–∏ –ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c836471-4276-4a11-9380-0603c4f4cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∏–º —ç–º–±–µ–¥–¥–µ—Ä\n",
    "embedder = SentenceTransformer(\"ai-forever/FRIDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "798ca722-e4c7-4b28-ba57-8bcb256388bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "\n",
    "def evaluate_similarity_frida(\n",
    "    questions: List[str], \n",
    "    generated_answers: List[str],\n",
    "    reference_answers: List[str]\n",
    ") -> List[float]:\n",
    "    \"\"\"\n",
    "    –í—ã—á–∏—Å–ª—è–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω—É—é –±–ª–∏–∑–æ—Å—Ç—å –º–µ–∂–¥—É —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∏ —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏\n",
    "    —Å –ø–æ–º–æ—â—å—é FRIDA SentenceTransformer.\n",
    "\n",
    "    :param questions: –°–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤\n",
    "    :param generated_answers: –°–ø–∏—Å–æ–∫ –æ—Ç–≤–µ—Ç–æ–≤, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö LLM.\n",
    "    :param reference_answers: –°–ø–∏—Å–æ–∫ —ç—Ç–∞–ª–æ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤.\n",
    "        \n",
    "    :return: –ö–æ—Å–∏–Ω—É—Å–Ω–∞—è –±–ª–∏–∑–æ—Å—Ç—å –ø–æ –∫–∞–∂–¥–æ–π –ø–∞—Ä–µ.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = (\n",
    "        [f\"search_document: {text}\" for text in generated_answers] +\n",
    "        [f\"search_document: {text}\" for text in reference_answers]\n",
    "    )\n",
    "\n",
    "    embeddings = embedder.encode(inputs, convert_to_tensor=True)\n",
    "\n",
    "    gen_embs = embeddings[:len(generated_answers)]\n",
    "    ref_embs = embeddings[len(generated_answers):]\n",
    "\n",
    "    sim_scores = (gen_embs @ ref_embs.T).diagonal().tolist()\n",
    "    print(len(sim_scores))\n",
    "    for i, (question, generated, reference) in enumerate(zip(questions, generated_answers, reference_answers)):\n",
    "        \n",
    "        print(f\"–í–æ–ø—Ä–æ—Å: {question}:\")\n",
    "        #print(f\"–û–∂–∏–¥–∞–ª–æ—Å—å:\\n{reference}\")\n",
    "        #print(f\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ:\\n{generated}\")\n",
    "        print(f\"cosine_similarity: {sim_scores[i]:.4f}\\n\")\n",
    "        print(100 * '*')\n",
    "\n",
    "    avg_sim = sum(sim_scores) / len(sim_scores)\n",
    "    print(\"\\n–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞\")\n",
    "    print(f\"–°—Ä–µ–¥–Ω–∏–π similarity: {avg_sim:.4f}\")\n",
    "    \n",
    "    return sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad0a6011-a63c-435f-a0a6-a7ea799a87ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# —Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã –∏ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã\n",
    "base_dir = \"questions\"\n",
    "\n",
    "questions = []\n",
    "reference_answers = []\n",
    "\n",
    "for country in os.listdir(base_dir):\n",
    "    country_path = os.path.join(base_dir, country)\n",
    "\n",
    "    if not os.path.isdir(country_path):\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(country_path):\n",
    "        if file.endswith(\".json\"):\n",
    "            file_path = os.path.join(country_path, file)\n",
    "\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            for item in data:\n",
    "                q = item.get(\"question\", \"\").strip()\n",
    "                a = item.get(\"answer\", \"\").strip()\n",
    "\n",
    "                questions.append(q)\n",
    "                reference_answers.append(a)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4f68b7c-28d6-4cd7-9971-6665567ec15f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset 66.20s/it]\n",
      "  6%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                           | 6/93 [06:43<1:37:34, 67.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m generated_answer \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m tqdm(questions):\n\u001b[1;32m----> 4\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      5\u001b[0m     generated_answer\u001b[38;5;241m.\u001b[39mappend(response)\n",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m, in \u001b[0;36mfinal_pipeline\u001b[1;34m(query, top_k, debug)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m–ù–∞–π–¥–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å —É—á–µ—Ç–æ–º –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m answer\n",
      "Cell \u001b[1;32mIn[6], line 22\u001b[0m, in \u001b[0;36mgenerate_answer\u001b[1;34m(query, context, max_new_tokens)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é LLM –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m:return: –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m         –¢—ã ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫.\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m         –ò—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124m         –û—Ç–≤–µ—Ç:\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124m         \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m response \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m–û—Ç–≤–µ—Ç:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;66;03m# –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:272\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[1;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(chats, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\transformers\\pipelines\\base.py:1301\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m   1294\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1298\u001b[0m         )\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\transformers\\pipelines\\base.py:1308\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[0;32m   1307\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[1;32m-> 1308\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1309\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\transformers\\pipelines\\base.py:1208\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[0;32m   1207\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1208\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(model_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mforward_params)\n\u001b[0;32m   1209\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\transformers\\pipelines\\text_generation.py:370\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[1;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m generate_kwargs:\n\u001b[0;32m    368\u001b[0m     generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration_config\n\u001b[1;32m--> 370\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgenerate(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgenerate_kwargs)\n\u001b[0;32m    371\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\transformers\\generation\\utils.py:2252\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2244\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2245\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2246\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[0;32m   2247\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2248\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2249\u001b[0m     )\n\u001b[0;32m   2251\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[1;32m-> 2252\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample(\n\u001b[0;32m   2253\u001b[0m         input_ids,\n\u001b[0;32m   2254\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2255\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2256\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2257\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2258\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   2259\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2260\u001b[0m     )\n\u001b[0;32m   2262\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[0;32m   2263\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2264\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2265\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2266\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2272\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\transformers\\generation\\utils.py:3254\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   3252\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   3253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3254\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3256\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[0;32m   3257\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[0;32m   3258\u001b[0m     outputs,\n\u001b[0;32m   3259\u001b[0m     model_kwargs,\n\u001b[0;32m   3260\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   3261\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:1163\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[0;32m   1160\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[1;32m-> 1163\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[0;32m   1164\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1165\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1166\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1167\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1168\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1169\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1170\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1171\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1172\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1173\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m   1174\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1175\u001b[0m )\n\u001b[0;32m   1177\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:913\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[1;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[0;32m    901\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    902\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    903\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         position_embeddings,\n\u001b[0;32m    911\u001b[0m     )\n\u001b[0;32m    912\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 913\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[0;32m    914\u001b[0m         hidden_states,\n\u001b[0;32m    915\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[0;32m    916\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m    917\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m    918\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    919\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m    920\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[0;32m    921\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[0;32m    922\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs,\n\u001b[0;32m    923\u001b[0m     )\n\u001b[0;32m    925\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:656\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    654\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m    655\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[1;32m--> 656\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[0;32m    659\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:242\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 242\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\bitsandbytes\\nn\\modules.py:990\u001b[0m, in \u001b[0;36mLinear8bitLt.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m x\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 990\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mbnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mhas_fp16_weights \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCB \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mCB\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:509\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(A, B, out, state, threshold, bias)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    508\u001b[0m     state\u001b[38;5;241m.\u001b[39mthreshold \u001b[38;5;241m=\u001b[39m threshold\n\u001b[1;32m--> 509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMatMul8bitLt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\torch\\autograd\\function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\bitsandbytes\\autograd\\_functions.py:326\u001b[0m, in \u001b[0;36mMatMul8bitLt.forward\u001b[1;34m(ctx, A, B, out, bias, state)\u001b[0m\n\u001b[0;32m    323\u001b[0m     CA, CAt, SCA, SCAt, outlier_cols \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mint8_double_quant(A\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat16), threshold\u001b[38;5;241m=\u001b[39mstate\u001b[38;5;241m.\u001b[39mthreshold)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;66;03m# Fast path\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     CA, SCA, outlier_cols \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint8_vectorwise_quant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    327\u001b[0m     CAt \u001b[38;5;241m=\u001b[39m SCAt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    329\u001b[0m has_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\bitsandbytes\\functional.py:2783\u001b[0m, in \u001b[0;36mint8_vectorwise_quant\u001b[1;34m(A, threshold)\u001b[0m\n\u001b[0;32m   2779\u001b[0m outlier_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   2782\u001b[0m     \u001b[38;5;66;03m# TODO we could improve perf of this\u001b[39;00m\n\u001b[1;32m-> 2783\u001b[0m     outliers \u001b[38;5;241m=\u001b[39m \u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold\n\u001b[0;32m   2785\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m outliers\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   2786\u001b[0m         outlier_cols \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margwhere(outliers\u001b[38;5;241m.\u001b[39many(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generated_answer = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    response = final_pipeline(question) \n",
    "    generated_answer.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e272f67b-5bdd-4154-806e-a9c2adb33f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–î–ª–∏–Ω–∞ –ë–µ—Ä–ª–∏–Ω—Å–∫–æ–π —Å—Ç–µ–Ω—ã —Å–æ—Å—Ç–∞–≤–ª—è–ª–∞ –æ–∫–æ–ª–æ 155 –∫–º, –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö 43,1 –∫–º –ø—Ä–∏—Ö–æ–¥–∏–ª–∏—Å—å –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –Ω–∞ –≥–æ—Ä–æ–¥, –∞ –≤—ã—Å–æ—Ç–∞ –¥–æ—Å—Ç–∏–≥–∞–ª–∞ 4,1 –º.',\n",
       " '–í –ë–µ—Ä–ª–∏–Ω–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è —Ç–∞–∫–∏–µ –º—É–∑–µ–∏, –∫–∞–∫ –ú—É–∑–µ–π –ë–æ–¥–µ, –ü–µ—Ä–≥–∞–º—Å–∫–∏–π –º—É–∑–µ–π, –°—Ç–∞—Ä—ã–π –º—É–∑–µ–π, –ù–æ–≤—ã–π –º—É–∑–µ–π –∏ –°—Ç–∞—Ä–∞—è –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –≥–∞–ª–µ—Ä–µ—è.',\n",
       " '–í –ë–µ—Ä–ª–∏–Ω–µ –º–æ–∂–Ω–æ –ø–æ—Å–µ—Ç–∏—Ç—å –æ–ø–µ—Ä—É, –º—é–∑–∏–∫–ª—ã, –∫–æ–Ω—Ü–µ—Ä—Ç—ã, –±–∞–ª–µ—Ç –∏ —Ç–µ–∞—Ç—Ä.',\n",
       " '–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –æ–ø–µ—Ä–Ω—ã–µ —Ç–µ–∞—Ç—Ä—ã –≤ –ë–µ—Ä–ª–∏–Ω–µ –≤–∫–ª—é—á–∞—é—Ç Staatsoper Unter den Linden, Komische Oper –∏ Deutsche Oper.',\n",
       " '–ú—é–∑–∏–∫–ª—ã –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ Friedrichstadt-Palast, Theater des Westens, Bluemax Theater, Admiralspalast –∏ Wintergarten.',\n",
       " '–ö–æ–Ω—Ü–µ—Ä—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç –≤ Philharmonie, Kammermusiksaal, Konzerthaus –∏ Kammermusiksaal Friedenau.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9b385c1-351e-4b4d-9cef-a407038cf6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "–í–æ–ø—Ä–æ—Å: –ö–∞–∫–æ–≤–∞ –±—ã–ª–∞ –¥–ª–∏–Ω–∞ –∏ –≤—ã—Å–æ—Ç–∞ –ë–µ—Ä–ª–∏–Ω—Å–∫–æ–π —Å—Ç–µ–Ω—ã?:\n",
      "cosine_similarity: 0.2486\n",
      "\n",
      "****************************************************************************************************\n",
      "–í–æ–ø—Ä–æ—Å: –ö–∞–∫–∏–µ –º—É–∑–µ–∏ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ë–µ—Ä–ª–∏–Ω–µ?:\n",
      "cosine_similarity: 0.5772\n",
      "\n",
      "****************************************************************************************************\n",
      "–í–æ–ø—Ä–æ—Å: –ö–∞–∫–∏–µ –≤–∏–¥—ã –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–π –º–æ–∂–Ω–æ –ø–æ—Å–µ—Ç–∏—Ç—å –≤ –ë–µ—Ä–ª–∏–Ω–µ?:\n",
      "cosine_similarity: 0.8087\n",
      "\n",
      "****************************************************************************************************\n",
      "–í–æ–ø—Ä–æ—Å: –ö–∞–∫–∏–µ –æ–ø–µ—Ä–Ω—ã–µ —Ç–µ–∞—Ç—Ä—ã –µ—Å—Ç—å –≤ –ë–µ—Ä–ª–∏–Ω–µ?:\n",
      "cosine_similarity: 0.7688\n",
      "\n",
      "****************************************************************************************************\n",
      "–í–æ–ø—Ä–æ—Å: –ì–¥–µ –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –º—é–∑–∏–∫–ª—ã –≤ –ë–µ—Ä–ª–∏–Ω–µ?:\n",
      "cosine_similarity: 0.6104\n",
      "\n",
      "****************************************************************************************************\n",
      "–í–æ–ø—Ä–æ—Å: –ì–¥–µ –ø—Ä–æ—Ö–æ–¥—è—Ç –∫–æ–Ω—Ü–µ—Ä—Ç—ã –≤ –ë–µ—Ä–ª–∏–Ω–µ?:\n",
      "cosine_similarity: 0.4874\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞\n",
      "–°—Ä–µ–¥–Ω–∏–π similarity: 0.5835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24862411618232727,\n",
       " 0.5771656632423401,\n",
       " 0.8087441325187683,\n",
       " 0.7687965035438538,\n",
       " 0.610448956489563,\n",
       " 0.4873986542224884]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_similarity_frida(questions, generated_answer, reference_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd12f5a-7d51-4e79-9228-a9cbb15cc954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
